{
  "hash": "e6818d88ca8a75a0359baf904594c5f1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 4: Spatial Predictive Analysis\"\nsubtitle: \"Chicago 311 Data\"\nauthor: \"Sujan Kakumanu\"\ndate: 11-17-2025\nformat: \n  html:\n    code-fold: show\n    toc: true\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\nexecute:\n  warning: false\n  message: false\n---\n\n# Setup\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n```\n:::\n\n\n# Data Loading & Exploration\nFirst, some contextual boundaries are being loaded. We have Chicago Police District boundaries, Police Beats (smaller than districts), and the City boundary itself.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271', quiet = TRUE) %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271', quiet = TRUE) %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\", quiet = TRUE) %>%\n  st_transform('ESRI:102271', quiet = TRUE)\n```\n:::\n\n\n::: callout-note\n## Coordinate Reference System\n\nWe're using `ESRI:102271` (Illinois State Plane East, NAD83, US Feet). This is appropriate for Chicago because:\n\n-   It minimizes distortion in this region\n-   Uses feet (common in US planning)\n-   Allows accurate distance calculations\n:::\n\nEventually, we will create predictive models for burglaries. Here, we load Chicago Burglary data.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(\"./data/burglaries.shp\", quiet = TRUE) %>% \n  st_transform('ESRI:102271', quiet = TRUE)\n\ncat(glue::glue(\"\n### Burglary Data Check\n\n**✓ Loaded burglary data**\n\n- **Number of burglaries:** {nrow(burglaries)}\n- **CRS:** {st_crs(burglaries)$input}\n- **Date range:** {min(burglaries$date, na.rm = TRUE)} to {max(burglaries$date, na.rm = TRUE)}\n\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### Burglary Data Check\n\n**✓ Loaded burglary data**\n\n- **Number of burglaries:** 7482\n- **CRS:** ESRI:102271\n- **Date range:** Inf to -Inf\n```\n\n\n:::\n:::\n\nOne predictor that will be explored is 311 Data focused on street light outages. Specifically, this data contains points where single street light outages were reported. I chose this feature mostly out of curiosity. Vacant buildings, abandoned cars, etc are examples of physcial properties that can be connected to crimes, but street light outages on a surface level seem less connected. \n\n::: {.cell}\n\n```{.r .cell-code}\nstreet_lights <- read_csv(\"./data/311_Single_Street_Light_Out.csv\")%>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n```\n:::\n\n\n## Visualizing Single Street Light Outages from 311 Data\n\n### Simple Choropleth Map\nFirst, I want to visualize the single lights outage data with a choropleth map using Chicago PD boundaries. This will not be the most insightful visualization, but I want to get an idea of the data before proceeding with other methods.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate street lights out by police district\nlights_by_district <- \n  policeDistricts %>%\n  st_join(street_lights) %>%\n  count(District, name = \"lights_out\")\n\n# Choropleth map\nggplot() +\n  geom_sf(data = lights_by_district, \n          aes(fill = lights_out), \n          color = \"white\", size = 0.3) +\n  scale_fill_viridis(option = \"plasma\", direction = 1) +\n  labs(\n    title = \"Single Street Light Outage 311 Reports by Police District\",\n    subtitle = \"Counts aggregated to Chicago Police District boundaries\",\n    fill = \"Reports\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](Kakumanu_Sujan_Assignment4_files/figure-html/visualize-by-district-1.png){width=672}\n:::\n:::\n\nHere, we see the greatest number of reports in southern, south-western, and north-western Police Districts, and lower numbers in central and northern ones.\n\n### Fishnet Grid and Visualization\nAs stated previously, arbitrary boundaries like police districts make analysis more complicated and less reliable for real-world conditions. Here, we use a 500m x 500m \"fishnet\" over the City of Chicago, where each grid cell has aggregated counts for 311 Single Light Outage complaints.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a 500mx500m fishnet\nfishnet_lights <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Aggregate burglaries to the same fishnet grid\nburglaries_fishnet <- st_join(burglaries, fishnet_lights, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join burglary counts to fishnet\nfishnet_lights <- fishnet_lights %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Spatial join: assign each street light to a grid cell\nlights_fishnet <- st_join(street_lights, fishnet_lights, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countLights = n())\n\n# Join back to fishnet (cells with zero lights will be NA → convert to 0)\nfishnet_lights <- fishnet_lights %>%\n  left_join(lights_fishnet, by = \"uniqueID\") %>%\n  mutate(countLights = replace_na(countLights, 0))\n\n# Finally, I want to filter out cells with zero counts, as that will mess wth future analysis\nfishnet_lights <- fishnet_lights %>%\n  filter(countLights > 0)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = fishnet_lights, aes(fill = countLights), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 0.5) +\n  scale_fill_viridis_c(\n    name = \"Street Lights Out\",\n    option = \"plasma\",\n    trans = \"sqrt\",\n    breaks = c(0, 10, 50, 200, 600)\n  ) +\n  labs(\n    title = \"Chicago Single Street Light Outage 311 Reports by Grid Cell\",\n    subtitle = \"500m x 500m cells. Chicago, IL\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](Kakumanu_Sujan_Assignment4_files/figure-html/visualize-with-fishnet-1.png){width=672}\n:::\n:::\n\nHere, the fishnet grid provides a more granular view of street light outages across the city. In the southernmost police district—which the choropleth map previously suggested had the highest number of 311 complaints—we now see substantial variation: much of the district has relatively few complaints, while hotspots appear in the northern portions. Similarly, northern and western Chicago contains concentrated pockets of higher complaint activity that are obscured when aggregated at the district level.\n\nWe can explore this spatial variation in the following section.\n\n### Spatial Feature Development\n\n#### k-Nearest Neighbor Features\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3.2 Nearest Neighbor Features\n# Coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet_lights))\nlights_coords <- st_coordinates(street_lights)\n\n# kNN distances\nnn_result <- get.knnx(lights_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet_lights <- fishnet_lights %>%\n  mutate(lights_out_nn = rowMeans(nn_result$nn.dist))\n\nsummary(fishnet_lights$lights_out_nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.89   29.32   45.95   66.50   75.31  625.47 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 3) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\nfishnet_lights_morans <- calculate_local_morans(fishnet_lights, \"countLights\", k = 5)\n\n# Visualize clusters\nggplot() +\n  geom_sf(data = fishnet_lights_morans, aes(fill = moran_class), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"black\", linewidth = 0.4) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Street Light Outage Clusters\",\n    subtitle = \"High-High = Hot spots of outages; k=3 neighbors\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](Kakumanu_Sujan_Assignment4_files/figure-html/morans-i-feature-1.png){width=672}\n:::\n:::\n\n\nThe calculate_local_morans function was provided in class. The function wraps R's localmoran() to automate spatial weight creation and classify cells into interpretable cluster types (High-High, Low-Low, etc.), which localmoran() doesn't provide—it only returns raw statistics.\n\nThe Local Moran's I results confirm clustering visible in the fishnet map, with High-High clusters concentrated in South Chicago where high outage counts are surrounded by other high-count cells. Areas of High-High and Low-Low cells can be considered as hotspots and coldspots respectively. This can be a useful parameter for the remainder of this report, so it is calculated below. In addition, we can calculate distances between every cell and the nearest hot and cold spots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet_lights_morans %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet_lights_morans <- fishnet_lights_morans %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet_lights_morans), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to single light outage hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet_lights_morans <- fishnet_lights_morans %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to single light outage hot spots\n  - Number of hot spot cells: 260 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"Low-Low\" cells (cold spots)\ncoldspots <- fishnet_lights_morans %>%\n  filter(moran_class == \"Low-Low\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest cold spot\nif (nrow(coldspots) > 0) {\n  fishnet_lights_morans <- fishnet_lights_morans %>%\n    mutate(\n      dist_to_coldspot = as.numeric(\n        st_distance(st_centroid(fishnet_lights_morans), coldspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to single light outage cold spots\\n\")\n  cat(\"  - Number of cold spot cells:\", nrow(coldspots), \"\\n\")\n} else {\n  fishnet_lights_morans <- fishnet_lights_morans %>%\n    mutate(dist_to_coldspot = 0)\n  cat(\"⚠ No significant cold spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to single light outage cold spots\n  - Number of cold spot cells: 180 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary statistics for distance features\ntibble(\n  Metric = c(\"Min\", \"Q1\", \"Median\", \"Mean\", \"Q3\", \"Max\"),\n  `Distance to Hot Spots` = summary(fishnet_lights_morans$dist_to_hotspot),\n  `Distance to Cold Spots` = summary(fishnet_lights_morans$dist_to_coldspot)\n) %>%\n  kable(\n    caption = \"Summary Statistics: Distance to Hot Spots and Cold Spots (feet)\",\n    digits = 0,\n    format.args = list(big.mark = \",\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Summary Statistics: Distance to Hot Spots and Cold Spots (feet)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:right;\"> Distance to Hot Spots </th>\n   <th style=\"text-align:right;\"> Distance to Cold Spots </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Min </td>\n   <td style=\"text-align:right;\"> 0.0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q1 </td>\n   <td style=\"text-align:right;\"> 707.1 </td>\n   <td style=\"text-align:right;\"> 1,000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Median </td>\n   <td style=\"text-align:right;\"> 1,581.1 </td>\n   <td style=\"text-align:right;\"> 1,803 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mean </td>\n   <td style=\"text-align:right;\"> 2,200.3 </td>\n   <td style=\"text-align:right;\"> 2,116 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q3 </td>\n   <td style=\"text-align:right;\"> 3,041.4 </td>\n   <td style=\"text-align:right;\"> 3,041 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Max </td>\n   <td style=\"text-align:right;\"> 10,965.9 </td>\n   <td style=\"text-align:right;\"> 6,265 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n# Count Regression Models\n\n## Poisson Regression\n\nSince light outages are simple counts, we can first try to create a Poisson Regression Model. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet\nfishnet_lights_morans <- st_join(\n  fishnet_lights_morans,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n)\n\n# Filter using base R subsetting\nfishnet_lights_morans <- fishnet_lights_morans[!is.na(fishnet_lights_morans$District), ]\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet_lights_morans$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet_lights_morans), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1611 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Fit Poisson regression predicting BURGLARIES\nmodel_poisson_burglary <- glm(\n  countBurglaries ~ countLights + lights_out_nn + dist_to_hotspot + dist_to_coldspot,\n  data = fishnet_lights_morans,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson_burglary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ countLights + lights_out_nn + \n    dist_to_hotspot + dist_to_coldspot, family = \"poisson\", data = fishnet_lights_morans)\n\nCoefficients:\n                     Estimate   Std. Error z value             Pr(>|z|)    \n(Intercept)       1.065585574  0.057115217  18.657 < 0.0000000000000002 ***\ncountLights       0.001557601  0.000103340  15.073 < 0.0000000000000002 ***\nlights_out_nn    -0.006864476  0.000500108 -13.726 < 0.0000000000000002 ***\ndist_to_hotspot  -0.000064158  0.000008971  -7.151    0.000000000000859 ***\ndist_to_coldspot  0.000100867  0.000009376  10.758 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6016.5  on 1610  degrees of freedom\nResidual deviance: 4411.3  on 1606  degrees of freedom\nAIC: 8477.6\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson_burglary, type = \"pearson\")^2) / \n              model_poisson_burglary$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 2.96 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n\n```{.r .cell-code}\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n⚠ Overdispersion detected! Consider Negative Binomial model.\n```\n\n\n:::\n:::\n\nThe Poisson regression shows that all four street light features are statistically significant predictors of burglary counts. Areas with more light outages tend to have more burglaries, and being closer to outage hotspots is associated with higher counts of burglaries as well. However, the high residual deviance confirms overdispersion, which is why we can try the Negative Binomial model instead.\n\n## Negative Binomial\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model predicting BURGLARIES\nmodel_nb_burglary <- glm.nb(\n  countBurglaries ~ countLights + lights_out_nn + dist_to_hotspot + dist_to_coldspot,\n  data = fishnet_lights_morans\n)\n\n# Summary\nsummary(model_nb_burglary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ countLights + lights_out_nn + \n    dist_to_hotspot + dist_to_coldspot, data = fishnet_lights_morans, \n    init.theta = 2.007649347, link = log)\n\nCoefficients:\n                    Estimate  Std. Error z value             Pr(>|z|)    \n(Intercept)       0.91119504  0.09865200   9.236 < 0.0000000000000002 ***\ncountLights       0.00197739  0.00019753  10.011 < 0.0000000000000002 ***\nlights_out_nn    -0.00797075  0.00077198 -10.325 < 0.0000000000000002 ***\ndist_to_hotspot  -0.00004062  0.00001388  -2.925              0.00344 ** \ndist_to_coldspot  0.00012039  0.00001698   7.092     0.00000000000132 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.0076) family taken to be 1)\n\n    Null deviance: 2445.8  on 1610  degrees of freedom\nResidual deviance: 1779.9  on 1606  degrees of freedom\nAIC: 7295.1\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.008 \n          Std. Err.:  0.121 \n\n 2 x log-likelihood:  -7283.051 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare models\ncat(\"\\n### Model Comparison (AIC - lower is better):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n### Model Comparison (AIC - lower is better):\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson_burglary), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 8477.6 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb_burglary), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 7295.1 \n```\n\n\n:::\n:::\n\nThe Negative Binomial model shows all predictors remain significant, with the same relationships: more light outages and closer proximity to hotspots are associated with higher burglary counts. The much lower AIC (7,295 vs 8,477.6) confirms this model performs better than Poisson.\n\n# Spatial Cross Validation\n\nStandard cross-validation randomly splits data, but with spatial data this means training on cells directly adjacent to test cells (spatial information leakage). **Leave-One-Group-Out (LOGO) Cross-Validation** addresses this by training on all police districts except one, then testing on the held-out district.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet_lights_morans %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    countLights,\n    lights_out_nn,\n    dist_to_hotspot,\n    dist_to_coldspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 1611 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet_model$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ countLights + lights_out_nn + \n      dist_to_hotspot + dist_to_coldspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 2.03 \n  Fold 2 / 22 - District 4 - MAE: 2.41 \n  Fold 3 / 22 - District 22 - MAE: 3.06 \n  Fold 4 / 22 - District 6 - MAE: 4.44 \n  Fold 5 / 22 - District 8 - MAE: 2.69 \n  Fold 6 / 22 - District 7 - MAE: 2.73 \n  Fold 7 / 22 - District 3 - MAE: 5.53 \n  Fold 8 / 22 - District 2 - MAE: 2.82 \n  Fold 9 / 22 - District 9 - MAE: 1.79 \n  Fold 10 / 22 - District 10 - MAE: 1.94 \n  Fold 11 / 22 - District 1 - MAE: 2.28 \n  Fold 12 / 22 - District 12 - MAE: 2.93 \n  Fold 13 / 22 - District 15 - MAE: 1.87 \n  Fold 14 / 22 - District 11 - MAE: 2.84 \n  Fold 15 / 22 - District 18 - MAE: 2.36 \n  Fold 16 / 22 - District 25 - MAE: 2.45 \n  Fold 17 / 22 - District 14 - MAE: 2.94 \n  Fold 18 / 22 - District 19 - MAE: 2 \n  Fold 19 / 22 - District 16 - MAE: 2.05 \n  Fold 20 / 22 - District 17 - MAE: 1.74 \n  Fold 21 / 22 - District 20 - MAE: 1.66 \n  Fold 22 / 22 - District 24 - MAE: 2.25 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.58 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.49 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  Metric = c(\"Mean MAE\", \"Mean RMSE\", \"Std Dev MAE\", \"Std Dev RMSE\"),\n  Value = c(\n    mean(cv_results$mae),\n    mean(cv_results$rmse),\n    sd(cv_results$mae),\n    sd(cv_results$rmse)\n  )\n) %>%\n  kable(\n    digits = 2,\n    caption = \"Overall Cross-Validation Performance\",\n    format.args = list(big.mark = \",\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Overall Cross-Validation Performance</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:right;\"> Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Mean MAE </td>\n   <td style=\"text-align:right;\"> 2.58 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mean RMSE </td>\n   <td style=\"text-align:right;\"> 3.49 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Std Dev MAE </td>\n   <td style=\"text-align:right;\"> 0.90 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Std Dev RMSE </td>\n   <td style=\"text-align:right;\"> 1.29 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join CV results to police districts for mapping\ndistricts_cv <- policeDistricts %>%\n  left_join(cv_results, by = c(\"District\" = \"test_district\"))\n\n# Map MAE by district\np1 <- ggplot() +\n  geom_sf(data = districts_cv, aes(fill = mae), color = \"white\", linewidth = 0.5) +\n  scale_fill_viridis_c(\n    name = \"MAE\",\n    option = \"plasma\",\n    direction = -1\n  ) +\n  labs(\n    title = \"Mean Absolute Error by District\"\n  ) +\n  theme_crime()\n\n# Map RMSE by district\np2 <- ggplot() +\n  geom_sf(data = districts_cv, aes(fill = rmse), color = \"white\", linewidth = 0.5) +\n  scale_fill_viridis_c(\n    name = \"RMSE\",\n    option = \"plasma\",\n    direction = -1\n  ) +\n  labs(\n    title = \"Root Mean Squared Error by District\"\n  ) +\n  theme_crime()\n\np1 + p2 +\n  plot_annotation(\n    title = \"Spatial Cross-Validation Performance\",\n    subtitle = \"Which districts are hardest to predict?\"\n  )\n```\n\n::: {.cell-output-display}\n![](Kakumanu_Sujan_Assignment4_files/figure-html/cv-visualization-1.png){width=1152}\n:::\n:::\n\n\n# Model Evaluation\n\n## Generate Final Predictions\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add predictions back to fishnet using existing model\nfishnet_lights_morans <- fishnet_lights_morans %>%\n  mutate(\n    prediction_nb = predict(model_nb_burglary, fishnet_lights_morans, type = \"response\")\n  )\n\ncat(\"✓ Generated final model predictions\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Generated final model predictions\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Mean predicted burglaries:\", round(mean(fishnet_lights_morans$prediction_nb, na.rm = TRUE), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Mean predicted burglaries: 3.81 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Mean actual burglaries:\", round(mean(fishnet_lights_morans$countBurglaries, na.rm = TRUE), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Mean actual burglaries: 3.73 \n```\n\n\n:::\n:::\n\n\n## Create KDE Baseline\n\nHere, we create a simple baseline using **Kernel Density Estimation (KDE)**. This is a simple baseline because it presents a null hypothesis that burglaries happen neaer where they happened before. If the more complicated model doesn't outperform this, we need to work on it.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1000 ft bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  \n  edge = TRUE\n)\n\n# Convert to terra raster\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet_lights_morans <- fishnet_lights_morans %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet_lights_morans),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\n# Normalize KDE to same scale as counts\nkde_sum <- sum(fishnet_lights_morans$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet_lights_morans$countBurglaries, na.rm = TRUE)\n\nfishnet_lights_morans <- fishnet_lights_morans %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\n## Compare Model vs KDE Baseline\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet_lights_morans, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries (2017)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet_lights_morans, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (2018)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet_lights_morans, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions (2018)\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries in Chicago\",\n  )\n```\n\n::: {.cell-output-display}\n![](Kakumanu_Sujan_Assignment4_files/figure-html/compare-models-1.png){width=1152}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet_lights_morans %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison (2017)\",\n    col.names = c(\"Approach\", \"MAE\", \"RMSE\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison (2017)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Approach </th>\n   <th style=\"text-align:right;\"> MAE </th>\n   <th style=\"text-align:right;\"> RMSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> model </td>\n   <td style=\"text-align:right;\"> 2.46 </td>\n   <td style=\"text-align:right;\"> 3.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> kde </td>\n   <td style=\"text-align:right;\"> 2.14 </td>\n   <td style=\"text-align:right;\"> 3.01 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Map Prediction Errors\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate errors\nfishnet_lights_morans <- fishnet_lights_morans %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors for negative binomial model\np1 <- ggplot() +\n  geom_sf(data = fishnet_lights_morans, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", \n    mid = \"white\", \n    high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet_lights_morans, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2 +\n  plot_annotation(\n    title = \"Where Does the Model Fail?\",\n    subtitle = \"Red = Under-prediction (actual > predicted), Blue = Over-prediction\"\n  )\n```\n\n::: {.cell-output-display}\n![](Kakumanu_Sujan_Assignment4_files/figure-html/prediction-errors-1.png){width=1152}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  Metric = c(\"Mean Error\", \"Mean Absolute Error\", \"RMSE\", \"Max Over-prediction\", \"Max Under-prediction\"),\n  `Negative Binomial` = c(\n    mean(fishnet_lights_morans$error_nb, na.rm = TRUE),\n    mean(fishnet_lights_morans$abs_error_nb, na.rm = TRUE),\n    sqrt(mean(fishnet_lights_morans$error_nb^2, na.rm = TRUE)),\n    min(fishnet_lights_morans$error_nb, na.rm = TRUE),\n    max(fishnet_lights_morans$error_nb, na.rm = TRUE)\n  ),\n  KDE = c(\n    mean(fishnet_lights_morans$error_kde, na.rm = TRUE),\n    mean(fishnet_lights_morans$abs_error_kde, na.rm = TRUE),\n    sqrt(mean(fishnet_lights_morans$error_kde^2, na.rm = TRUE)),\n    min(fishnet_lights_morans$error_kde, na.rm = TRUE),\n    max(fishnet_lights_morans$error_kde, na.rm = TRUE)\n  )\n) %>%\n  kable(\n    digits = 2,\n    caption = \"Prediction Error Summary\",\n    format.args = list(big.mark = \",\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Prediction Error Summary</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:right;\"> Negative Binomial </th>\n   <th style=\"text-align:right;\"> KDE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Mean Error </td>\n   <td style=\"text-align:right;\"> -0.08 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mean Absolute Error </td>\n   <td style=\"text-align:right;\"> 2.46 </td>\n   <td style=\"text-align:right;\"> 2.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:right;\"> 3.52 </td>\n   <td style=\"text-align:right;\"> 3.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Max Over-prediction </td>\n   <td style=\"text-align:right;\"> -13.45 </td>\n   <td style=\"text-align:right;\"> -7.76 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Max Under-prediction </td>\n   <td style=\"text-align:right;\"> 34.17 </td>\n   <td style=\"text-align:right;\"> 30.16 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n",
    "supporting": [
      "Kakumanu_Sujan_Assignment4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}